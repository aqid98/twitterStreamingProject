{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "hello\n"}], "source": "print(\"hello\")"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Starting ssc\nSleeping .....zzzz..\n-------------------------------------------\nTime: 2021-10-24 15:26:55\n-------------------------------------------\n('#2yrsofindustryhitbigil', 1)\n('#beast', 1)\n('#master', 1)\n\n-------------------------------------------\nTime: 2021-10-24 15:27:00\n-------------------------------------------\n('#lalice', 3)\n('#blackpink', 3)\n('#lalisa', 3)\n('#2yrsofindustryhitbigil', 1)\n('#beast', 1)\n('#rainilealsat', 1)\n('#bjkvgs', 1)\n('#100daysofcode', 1)\n('#bigdata', 1)\n('#pytorch', 1)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:05\n-------------------------------------------\n('#lalice', 9)\n('#blackpink', 9)\n('#lalisa', 9)\n('#datascience', 6)\n('#100daysofcode', 5)\n('#bigdata', 5)\n('#pytorch', 5)\n('#dataanalytics', 5)\n('#machinelearning', 5)\n('#python', 5)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:10\n-------------------------------------------\n('#lalice', 11)\n('#blackpink', 11)\n('#lalisa', 11)\n('#datascience', 7)\n('#100daysofcode', 6)\n('#bigdata', 6)\n('#machinelearning', 6)\n('#python', 6)\n('#pytorch', 5)\n('#dataanalytics', 5)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:15\n-------------------------------------------\n('#lalice', 12)\n('#blackpink', 12)\n('#lalisa', 12)\n('#machinelearning', 8)\n('#datascience', 8)\n('#100daysofcode', 7)\n('#bigdata', 7)\n('#python', 6)\n('#pytorch', 5)\n('#dataanalytics', 5)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:20\n-------------------------------------------\n('#lalice', 13)\n('#blackpink', 13)\n('#lalisa', 13)\n('#100daysofcode', 8)\n('#machinelearning', 8)\n('#datascience', 8)\n('#bigdata', 7)\n('#python', 6)\n('#pytorch', 5)\n('#dataanalytics', 5)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:25\n-------------------------------------------\n('#lalice', 15)\n('#blackpink', 15)\n('#lalisa', 15)\n('#100daysofcode', 9)\n('#machinelearning', 9)\n('#datascience', 9)\n('#bigdata', 8)\n('#python', 7)\n('#bigil', 7)\n('#pytorch', 6)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:30\n-------------------------------------------\n('#lalice', 18)\n('#blackpink', 18)\n('#lalisa', 18)\n('#machinelearning', 10)\n('#100daysofcode', 9)\n('#datascience', 9)\n('#bigdata', 8)\n('#python', 7)\n('#bigil', 7)\n('#beast', 6)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:35\n-------------------------------------------\n('#lalice', 19)\n('#blackpink', 19)\n('#lalisa', 19)\n('#machinelearning', 10)\n('#bigil', 10)\n('#beast', 9)\n('#100daysofcode', 9)\n('#datascience', 9)\n('#2yrsofindustryhitbigil', 8)\n('#bigdata', 8)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:40\n-------------------------------------------\n('#lalice', 23)\n('#blackpink', 23)\n('#lalisa', 23)\n('#machinelearning', 10)\n('#bigil', 10)\n('#beast', 9)\n('#100daysofcode', 9)\n('#datascience', 9)\n('#2yrsofindustryhitbigil', 8)\n('#bigdata', 8)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:45\n-------------------------------------------\n('#lalice', 25)\n('#blackpink', 25)\n('#lalisa', 25)\n('#bigil', 12)\n('#machinelearning', 11)\n('#bigdata', 10)\n('#datascience', 10)\n('#beast', 9)\n('#100daysofcode', 9)\n('#2yrsofindustryhitbigil', 8)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:50\n-------------------------------------------\n('#lalice', 29)\n('#blackpink', 29)\n('#lalisa', 29)\n('#bigil', 12)\n('#machinelearning', 11)\n('#bigdata', 10)\n('#datascience', 10)\n('#beast', 9)\n('#100daysofcode', 9)\n('#2yrsofindustryhitbigil', 8)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:27:50\n-------------------------------------------\n('movie', 287, datetime.datetime(2021, 10, 24, 15, 27, 50))\n('good', 17, datetime.datetime(2021, 10, 24, 15, 27, 50))\n('ai', 177, datetime.datetime(2021, 10, 24, 15, 27, 50))\n('spark', 5, datetime.datetime(2021, 10, 24, 15, 27, 50))\n('data', 2, datetime.datetime(2021, 10, 24, 15, 27, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:27:55\n-------------------------------------------\n('#lalice', 30)\n('#blackpink', 30)\n('#lalisa', 30)\n('#bigil', 12)\n('#bigdata', 11)\n('#machinelearning', 11)\n('#datascience', 11)\n('#beast', 9)\n('#100daysofcode', 9)\n('#python', 9)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:00\n-------------------------------------------\n('#lalice', 31)\n('#blackpink', 31)\n('#lalisa', 31)\n('#bigil', 13)\n('#bigdata', 11)\n('#machinelearning', 11)\n('#datascience', 11)\n('#beast', 9)\n('#100daysofcode', 9)\n('#python', 9)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:05\n-------------------------------------------\n('#lalice', 33)\n('#blackpink', 33)\n('#lalisa', 33)\n('#bigil', 13)\n('#bigdata', 11)\n('#machinelearning', 11)\n('#datascience', 11)\n('#beast', 9)\n('#100daysofcode', 9)\n('#python', 9)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:10\n-------------------------------------------\n('#lalice', 37)\n('#blackpink', 37)\n('#lalisa', 37)\n('#bigil', 13)\n('#bigdata', 12)\n('#machinelearning', 12)\n('#datascience', 12)\n('#beast', 10)\n('#100daysofcode', 10)\n('#python', 10)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:15\n-------------------------------------------\n('#lalice', 38)\n('#blackpink', 38)\n('#lalisa', 38)\n('#bigdata', 14)\n('#machinelearning', 14)\n('#datascience', 14)\n('#bigil', 14)\n('#100daysofcode', 12)\n('#python', 12)\n('#pytorch', 11)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:20\n-------------------------------------------\n('#lalice', 39)\n('#blackpink', 39)\n('#lalisa', 39)\n('#machinelearning', 18)\n('#bigdata', 17)\n('#datascience', 17)\n('#bigil', 16)\n('#100daysofcode', 15)\n('#python', 15)\n('#pytorch', 14)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:25\n-------------------------------------------\n('#lalice', 40)\n('#blackpink', 40)\n('#lalisa', 40)\n('#machinelearning', 20)\n('#bigdata', 18)\n('#datascience', 18)\n('#100daysofcode', 16)\n('#python', 16)\n('#bigil', 16)\n('#pytorch', 15)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:30\n-------------------------------------------\n('#lalice', 41)\n('#blackpink', 41)\n('#lalisa', 41)\n('#machinelearning', 21)\n('#datascience', 20)\n('#bigil', 19)\n('#100daysofcode', 18)\n('#bigdata', 18)\n('#python', 16)\n('#beast', 15)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:35\n-------------------------------------------\n('#lalice', 44)\n('#blackpink', 44)\n('#lalisa', 44)\n('#machinelearning', 21)\n('#bigil', 21)\n('#datascience', 20)\n('#100daysofcode', 18)\n('#bigdata', 18)\n('#beast', 16)\n('#python', 16)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:40\n-------------------------------------------\n('#lalice', 48)\n('#blackpink', 48)\n('#lalisa', 48)\n('#bigil', 23)\n('#machinelearning', 21)\n('#datascience', 21)\n('#100daysofcode', 19)\n('#bigdata', 18)\n('#ai', 17)\n('#beast', 16)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:45\n-------------------------------------------\n('#lalice', 53)\n('#blackpink', 53)\n('#lalisa', 53)\n('#bigil', 23)\n('#machinelearning', 21)\n('#datascience', 21)\n('#100daysofcode', 19)\n('#ai', 19)\n('#bigdata', 18)\n('#beast', 16)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:50\n-------------------------------------------\n('#lalice', 56)\n('#blackpink', 56)\n('#lalisa', 56)\n('#bigil', 27)\n('#machinelearning', 22)\n('#datascience', 21)\n('#ai', 20)\n('#100daysofcode', 19)\n('#bigdata', 18)\n('#beast', 17)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:28:50\n-------------------------------------------\n('movie', 294, datetime.datetime(2021, 10, 24, 15, 28, 50))\n('good', 13, datetime.datetime(2021, 10, 24, 15, 28, 50))\n('ai', 173, datetime.datetime(2021, 10, 24, 15, 28, 50))\n('spark', 5, datetime.datetime(2021, 10, 24, 15, 28, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:28:55\n-------------------------------------------\n('#lalice', 57)\n('#blackpink', 57)\n('#lalisa', 57)\n('#bigil', 27)\n('#machinelearning', 22)\n('#datascience', 21)\n('#ai', 21)\n('#100daysofcode', 19)\n('#beast', 18)\n('#bigdata', 18)\n...\n\n"}, {"name": "stdout", "output_type": "stream", "text": "-------------------------------------------\nTime: 2021-10-24 15:29:00\n-------------------------------------------\n('#lalice', 61)\n('#blackpink', 61)\n('#lalisa', 61)\n('#bigil', 27)\n('#machinelearning', 22)\n('#ai', 22)\n('#datascience', 21)\n('#100daysofcode', 20)\n('#beast', 19)\n('#2yrsofindustryhitbigil', 18)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:05\n-------------------------------------------\n('#lalice', 64)\n('#blackpink', 64)\n('#lalisa', 64)\n('#bigil', 29)\n('#machinelearning', 22)\n('#ai', 22)\n('#datascience', 21)\n('#100daysofcode', 20)\n('#2yrsofindustryhitbigil', 19)\n('#beast', 19)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:10\n-------------------------------------------\n('#lalice', 64)\n('#blackpink', 64)\n('#lalisa', 64)\n('#bigil', 29)\n('#ai', 24)\n('#100daysofcode', 22)\n('#machinelearning', 22)\n('#datascience', 21)\n('#2yrsofindustryhitbigil', 20)\n('#beast', 20)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:15\n-------------------------------------------\n('#lalice', 66)\n('#blackpink', 66)\n('#lalisa', 66)\n('#bigil', 29)\n('#ai', 29)\n('#100daysofcode', 23)\n('#machinelearning', 22)\n('#datascience', 21)\n('#2yrsofindustryhitbigil', 20)\n('#beast', 20)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:20\n-------------------------------------------\n('#lalice', 68)\n('#blackpink', 68)\n('#lalisa', 68)\n('#bigil', 32)\n('#ai', 29)\n('#100daysofcode', 23)\n('#machinelearning', 22)\n('#2yrsofindustryhitbigil', 21)\n('#beast', 21)\n('#datascience', 21)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:25\n-------------------------------------------\n('#lalice', 68)\n('#blackpink', 68)\n('#lalisa', 68)\n('#bigil', 34)\n('#ai', 29)\n('#100daysofcode', 23)\n('#2yrsofindustryhitbigil', 22)\n('#beast', 22)\n('#machinelearning', 22)\n('#datascience', 21)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:30\n-------------------------------------------\n('#lalice', 70)\n('#blackpink', 70)\n('#lalisa', 70)\n('#bigil', 36)\n('#ai', 30)\n('#2yrsofindustryhitbigil', 23)\n('#beast', 23)\n('#100daysofcode', 23)\n('#machinelearning', 22)\n('#datascience', 21)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:35\n-------------------------------------------\n('#lalice', 71)\n('#blackpink', 71)\n('#lalisa', 71)\n('#bigil', 36)\n('#ai', 31)\n('#2yrsofindustryhitbigil', 23)\n('#beast', 23)\n('#100daysofcode', 23)\n('#machinelearning', 22)\n('#datascience', 22)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:40\n-------------------------------------------\n('#lalice', 72)\n('#blackpink', 72)\n('#lalisa', 72)\n('#bigil', 38)\n('#ai', 32)\n('#2yrsofindustryhitbigil', 24)\n('#beast', 24)\n('#machinelearning', 24)\n('#100daysofcode', 23)\n('#datascience', 22)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:45\n-------------------------------------------\n('#lalice', 74)\n('#blackpink', 74)\n('#lalisa', 74)\n('#bigil', 39)\n('#ai', 32)\n('#beast', 25)\n('#2yrsofindustryhitbigil', 24)\n('#machinelearning', 24)\n('#100daysofcode', 23)\n('#master', 22)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:50\n-------------------------------------------\n('#lalice', 77)\n('#blackpink', 77)\n('#lalisa', 77)\n('#bigil', 39)\n('#ai', 33)\n('#beast', 26)\n('#2yrsofindustryhitbigil', 25)\n('#machinelearning', 24)\n('#100daysofcode', 23)\n('#master', 22)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:29:50\n-------------------------------------------\n('ai', 174, datetime.datetime(2021, 10, 24, 15, 29, 50))\n('movie', 287, datetime.datetime(2021, 10, 24, 15, 29, 50))\n('good', 16, datetime.datetime(2021, 10, 24, 15, 29, 50))\n('spark', 5, datetime.datetime(2021, 10, 24, 15, 29, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:29:55\n-------------------------------------------\n('#lalice', 80)\n('#blackpink', 80)\n('#lalisa', 80)\n('#bigil', 40)\n('#ai', 33)\n('#beast', 26)\n('#2yrsofindustryhitbigil', 25)\n('#machinelearning', 25)\n('#100daysofcode', 24)\n('#datascience', 23)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:00\n-------------------------------------------\n('#lalice', 82)\n('#blackpink', 82)\n('#lalisa', 82)\n('#bigil', 40)\n('#ai', 33)\n('#machinelearning', 27)\n('#beast', 26)\n('#100daysofcode', 26)\n('#2yrsofindustryhitbigil', 25)\n('#datascience', 25)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:05\n-------------------------------------------\n('#lalice', 85)\n('#blackpink', 85)\n('#lalisa', 85)\n('#bigil', 40)\n('#ai', 33)\n('#machinelearning', 29)\n('#beast', 28)\n('#100daysofcode', 28)\n('#datascience', 27)\n('#2yrsofindustryhitbigil', 26)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:10\n-------------------------------------------\n('#lalice', 85)\n('#blackpink', 85)\n('#lalisa', 85)\n('#bigil', 42)\n('#ai', 36)\n('#machinelearning', 31)\n('#datascience', 31)\n('#beast', 30)\n('#100daysofcode', 30)\n('#bigdata', 29)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:15\n-------------------------------------------\n('#lalice', 87)\n('#blackpink', 87)\n('#lalisa', 87)\n('#bigil', 42)\n('#ai', 41)\n('#datascience', 32)\n('#machinelearning', 31)\n('#beast', 30)\n('#100daysofcode', 30)\n('#bigdata', 30)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:20\n-------------------------------------------\n('#lalice', 90)\n('#blackpink', 90)\n('#lalisa', 90)\n('#bigil', 45)\n('#ai', 41)\n('#beast', 32)\n('#datascience', 32)\n('#machinelearning', 31)\n('#2yrsofindustryhitbigil', 30)\n('#100daysofcode', 30)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:25\n-------------------------------------------\n('#lalice', 93)\n('#blackpink', 93)\n('#lalisa', 93)\n('#bigil', 45)\n('#ai', 44)\n('#datascience', 34)\n('#beast', 33)\n('#machinelearning', 32)\n('#bigdata', 31)\n('#2yrsofindustryhitbigil', 30)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:30\n-------------------------------------------\n('#lalice', 96)\n('#blackpink', 96)\n('#lalisa', 96)\n('#bigil', 47)\n('#ai', 45)\n('#beast', 34)\n('#datascience', 34)\n('#machinelearning', 32)\n('#2yrsofindustryhitbigil', 31)\n('#bigdata', 31)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:35\n-------------------------------------------\n('#lalice', 96)\n('#blackpink', 96)\n('#lalisa', 96)\n('#bigil', 49)\n('#ai', 46)\n('#beast', 35)\n('#datascience', 35)\n('#machinelearning', 33)\n('#bigdata', 32)\n('#2yrsofindustryhitbigil', 31)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:40\n-------------------------------------------\n('#lalice', 99)\n('#blackpink', 99)\n('#lalisa', 99)\n('#bigil', 50)\n('#ai', 46)\n('#beast', 36)\n('#datascience', 35)\n('#machinelearning', 33)\n('#bigdata', 32)\n('#master', 32)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:45\n-------------------------------------------\n('#lalice', 100)\n('#blackpink', 100)\n('#lalisa', 100)\n('#bigil', 50)\n('#ai', 46)\n('#beast', 37)\n('#datascience', 35)\n('#master', 33)\n('#machinelearning', 33)\n('#bigdata', 32)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:50\n-------------------------------------------\n('#lalice', 101)\n('#blackpink', 101)\n('#lalisa', 101)\n('#bigil', 50)\n('#ai', 47)\n('#beast', 37)\n('#datascience', 35)\n('#master', 33)\n('#machinelearning', 33)\n('#bigdata', 32)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:30:50\n-------------------------------------------\n('movie', 322, datetime.datetime(2021, 10, 24, 15, 30, 50))\n('ai', 164, datetime.datetime(2021, 10, 24, 15, 30, 50))\n('good', 4, datetime.datetime(2021, 10, 24, 15, 30, 50))\n('data', 4, datetime.datetime(2021, 10, 24, 15, 30, 50))\n('spark', 6, datetime.datetime(2021, 10, 24, 15, 30, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:30:55\n-------------------------------------------\n('#lalice', 105)\n('#blackpink', 105)\n('#lalisa', 105)\n('#bigil', 51)\n('#ai', 48)\n('#beast', 37)\n('#datascience', 35)\n('#master', 33)\n('#machinelearning', 33)\n('#bigdata', 32)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:00\n-------------------------------------------\n('#lalice', 111)\n('#blackpink', 111)\n('#lalisa', 111)\n('#bigil', 51)\n('#ai', 48)\n('#beast', 39)\n('#datascience', 35)\n('#master', 34)\n('#bigdata', 33)\n('#machinelearning', 33)\n...\n\n"}, {"name": "stdout", "output_type": "stream", "text": "-------------------------------------------\nTime: 2021-10-24 15:31:05\n-------------------------------------------\n('#lalice', 112)\n('#blackpink', 112)\n('#lalisa', 112)\n('#bigil', 51)\n('#ai', 48)\n('#beast', 39)\n('#datascience', 35)\n('#master', 34)\n('#bigdata', 33)\n('#machinelearning', 33)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:10\n-------------------------------------------\n('#lalice', 114)\n('#blackpink', 114)\n('#lalisa', 114)\n('#bigil', 55)\n('#ai', 48)\n('#beast', 40)\n('#master', 35)\n('#datascience', 35)\n('#2yrsofindustryhitbigil', 33)\n('#bigdata', 33)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:15\n-------------------------------------------\n('#lalice', 114)\n('#blackpink', 114)\n('#lalisa', 114)\n('#bigil', 56)\n('#ai', 49)\n('#beast', 40)\n('#master', 35)\n('#datascience', 35)\n('#2yrsofindustryhitbigil', 33)\n('#bigdata', 33)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:20\n-------------------------------------------\n('#lalice', 114)\n('#blackpink', 114)\n('#lalisa', 114)\n('#bigil', 56)\n('#ai', 49)\n('#beast', 40)\n('#master', 35)\n('#datascience', 35)\n('#2yrsofindustryhitbigil', 33)\n('#bigdata', 33)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:25\n-------------------------------------------\n('#lalice', 117)\n('#blackpink', 117)\n('#lalisa', 117)\n('#bigil', 56)\n('#ai', 50)\n('#beast', 40)\n('#master', 35)\n('#datascience', 35)\n('#2yrsofindustryhitbigil', 33)\n('#bigdata', 33)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:30\n-------------------------------------------\n('#lalice', 117)\n('#blackpink', 117)\n('#lalisa', 117)\n('#bigil', 58)\n('#ai', 51)\n('#beast', 41)\n('#master', 36)\n('#datascience', 36)\n('#2yrsofindustryhitbigil', 34)\n('#bigdata', 33)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:35\n-------------------------------------------\n('#lalice', 118)\n('#blackpink', 118)\n('#lalisa', 118)\n('#bigil', 59)\n('#ai', 54)\n('#beast', 41)\n('#master', 36)\n('#datascience', 36)\n('#2yrsofindustryhitbigil', 34)\n('#bigdata', 34)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:40\n-------------------------------------------\n('#lalice', 121)\n('#blackpink', 121)\n('#lalisa', 121)\n('#bigil', 63)\n('#ai', 55)\n('#beast', 42)\n('#master', 37)\n('#machinelearning', 36)\n('#datascience', 36)\n('#2yrsofindustryhitbigil', 35)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:45\n-------------------------------------------\n('#lalice', 121)\n('#blackpink', 121)\n('#lalisa', 121)\n('#bigil', 65)\n('#ai', 58)\n('#beast', 42)\n('#master', 37)\n('#machinelearning', 37)\n('#datascience', 37)\n('#bigdata', 36)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:50\n-------------------------------------------\n('#lalice', 125)\n('#blackpink', 125)\n('#lalisa', 125)\n('#bigil', 66)\n('#ai', 60)\n('#beast', 45)\n('#master', 40)\n('#datascience', 39)\n('#machinelearning', 38)\n('#bigdata', 37)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:31:50\n-------------------------------------------\n('ai', 160, datetime.datetime(2021, 10, 24, 15, 31, 50))\n('movie', 282, datetime.datetime(2021, 10, 24, 15, 31, 50))\n('good', 15, datetime.datetime(2021, 10, 24, 15, 31, 50))\n('spark', 3, datetime.datetime(2021, 10, 24, 15, 31, 50))\n('data', 2, datetime.datetime(2021, 10, 24, 15, 31, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:31:55\n-------------------------------------------\n('#lalice', 127)\n('#blackpink', 127)\n('#lalisa', 127)\n('#bigil', 69)\n('#ai', 60)\n('#beast', 46)\n('#master', 41)\n('#datascience', 40)\n('#machinelearning', 38)\n('#2yrsofindustryhitbigil', 37)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:00\n-------------------------------------------\n('#lalice', 130)\n('#blackpink', 130)\n('#lalisa', 130)\n('#bigil', 70)\n('#ai', 61)\n('#beast', 46)\n('#datascience', 42)\n('#master', 41)\n('#bigdata', 39)\n('#machinelearning', 39)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:05\n-------------------------------------------\n('#lalice', 131)\n('#blackpink', 131)\n('#lalisa', 131)\n('#bigil', 70)\n('#ai', 62)\n('#beast', 47)\n('#datascience', 43)\n('#master', 41)\n('#machinelearning', 40)\n('#bigdata', 39)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:10\n-------------------------------------------\n('#lalice', 131)\n('#blackpink', 131)\n('#lalisa', 131)\n('#bigil', 70)\n('#ai', 64)\n('#beast', 47)\n('#datascience', 43)\n('#master', 41)\n('#machinelearning', 40)\n('#bigdata', 39)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:15\n-------------------------------------------\n('#lalice', 134)\n('#blackpink', 134)\n('#lalisa', 134)\n('#bigil', 70)\n('#ai', 64)\n('#beast', 47)\n('#datascience', 43)\n('#master', 41)\n('#machinelearning', 41)\n('#bigdata', 39)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:20\n-------------------------------------------\n('#lalice', 134)\n('#blackpink', 134)\n('#lalisa', 134)\n('#bigil', 71)\n('#ai', 64)\n('#beast', 47)\n('#datascience', 43)\n('#master', 42)\n('#machinelearning', 41)\n('#2yrsofindustryhitbigil', 39)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:25\n-------------------------------------------\n('#lalice', 135)\n('#blackpink', 135)\n('#lalisa', 135)\n('#bigil', 72)\n('#ai', 64)\n('#beast', 48)\n('#datascience', 44)\n('#master', 42)\n('#machinelearning', 42)\n('#2yrsofindustryhitbigil', 40)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:30\n-------------------------------------------\n('#lalice', 137)\n('#blackpink', 137)\n('#lalisa', 137)\n('#bigil', 72)\n('#ai', 65)\n('#beast', 48)\n('#datascience', 44)\n('#master', 42)\n('#machinelearning', 42)\n('#2yrsofindustryhitbigil', 40)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:35\n-------------------------------------------\n('#lalice', 140)\n('#blackpink', 140)\n('#lalisa', 140)\n('#bigil', 74)\n('#ai', 65)\n('#beast', 48)\n('#datascience', 45)\n('#machinelearning', 44)\n('#master', 43)\n('#2yrsofindustryhitbigil', 40)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:40\n-------------------------------------------\n('#lalice', 142)\n('#blackpink', 142)\n('#lalisa', 142)\n('#bigil', 74)\n('#ai', 65)\n('#beast', 49)\n('#datascience', 47)\n('#machinelearning', 46)\n('#master', 43)\n('#bigdata', 42)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:45\n-------------------------------------------\n('#lalice', 143)\n('#blackpink', 143)\n('#lalisa', 143)\n('#bigil', 76)\n('#ai', 65)\n('#beast', 50)\n('#machinelearning', 50)\n('#datascience', 50)\n('#bigdata', 45)\n('#2yrsofindustryhitbigil', 43)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:50\n-------------------------------------------\n('#lalice', 145)\n('#blackpink', 145)\n('#lalisa', 145)\n('#bigil', 77)\n('#ai', 66)\n('#datascience', 53)\n('#machinelearning', 52)\n('#beast', 50)\n('#bigdata', 46)\n('#master', 44)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:32:50\n-------------------------------------------\n('ai', 165, datetime.datetime(2021, 10, 24, 15, 32, 50))\n('movie', 276, datetime.datetime(2021, 10, 24, 15, 32, 50))\n('good', 18, datetime.datetime(2021, 10, 24, 15, 32, 50))\n('data', 4, datetime.datetime(2021, 10, 24, 15, 32, 50))\n('spark', 4, datetime.datetime(2021, 10, 24, 15, 32, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:32:55\n-------------------------------------------\n('#lalice', 146)\n('#blackpink', 146)\n('#lalisa', 146)\n('#bigil', 78)\n('#ai', 68)\n('#datascience', 54)\n('#machinelearning', 53)\n('#beast', 51)\n('#bigdata', 47)\n('#master', 45)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:00\n-------------------------------------------\n('#lalice', 150)\n('#blackpink', 150)\n('#lalisa', 150)\n('#bigil', 78)\n('#ai', 70)\n('#datascience', 56)\n('#machinelearning', 53)\n('#beast', 52)\n('#bigdata', 47)\n('#master', 46)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:05\n-------------------------------------------\n('#lalice', 150)\n('#blackpink', 150)\n('#lalisa', 150)\n('#bigil', 78)\n('#ai', 70)\n('#datascience', 56)\n('#machinelearning', 53)\n('#beast', 52)\n('#bigdata', 47)\n('#master', 46)\n...\n\n"}, {"name": "stdout", "output_type": "stream", "text": "-------------------------------------------\nTime: 2021-10-24 15:33:10\n-------------------------------------------\n('#lalice', 153)\n('#blackpink', 153)\n('#lalisa', 153)\n('#bigil', 78)\n('#ai', 72)\n('#datascience', 56)\n('#machinelearning', 55)\n('#beast', 53)\n('#bigdata', 47)\n('#master', 47)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:15\n-------------------------------------------\n('#lalice', 155)\n('#blackpink', 155)\n('#lalisa', 155)\n('#bigil', 79)\n('#ai', 73)\n('#datascience', 58)\n('#machinelearning', 55)\n('#beast', 54)\n('#master', 48)\n('#bigdata', 47)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:20\n-------------------------------------------\n('#lalice', 157)\n('#blackpink', 157)\n('#lalisa', 157)\n('#bigil', 80)\n('#ai', 76)\n('#datascience', 60)\n('#machinelearning', 57)\n('#beast', 54)\n('#master', 48)\n('#bigdata', 47)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:25\n-------------------------------------------\n('#lalice', 158)\n('#blackpink', 158)\n('#lalisa', 158)\n('#bigil', 82)\n('#ai', 77)\n('#datascience', 61)\n('#machinelearning', 58)\n('#beast', 56)\n('#master', 50)\n('#2yrsofindustryhitbigil', 47)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:30\n-------------------------------------------\n('#lalice', 160)\n('#blackpink', 160)\n('#lalisa', 160)\n('#bigil', 83)\n('#ai', 78)\n('#datascience', 61)\n('#machinelearning', 59)\n('#beast', 57)\n('#master', 51)\n('#2yrsofindustryhitbigil', 49)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:35\n-------------------------------------------\n('#lalice', 161)\n('#blackpink', 161)\n('#lalisa', 161)\n('#bigil', 84)\n('#ai', 81)\n('#datascience', 62)\n('#machinelearning', 61)\n('#beast', 58)\n('#master', 52)\n('#2yrsofindustryhitbigil', 49)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:40\n-------------------------------------------\n('#lalice', 161)\n('#blackpink', 161)\n('#lalisa', 161)\n('#bigil', 86)\n('#ai', 82)\n('#datascience', 63)\n('#machinelearning', 62)\n('#beast', 60)\n('#master', 54)\n('#2yrsofindustryhitbigil', 51)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:45\n-------------------------------------------\n('#lalice', 162)\n('#blackpink', 162)\n('#lalisa', 162)\n('#bigil', 88)\n('#ai', 82)\n('#beast', 63)\n('#datascience', 63)\n('#machinelearning', 62)\n('#master', 57)\n('#2yrsofindustryhitbigil', 54)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:50\n-------------------------------------------\n('#lalice', 165)\n('#blackpink', 165)\n('#lalisa', 165)\n('#bigil', 88)\n('#ai', 82)\n('#beast', 64)\n('#datascience', 63)\n('#machinelearning', 62)\n('#master', 58)\n('#2yrsofindustryhitbigil', 54)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:33:50\n-------------------------------------------\n('movie', 309, datetime.datetime(2021, 10, 24, 15, 33, 50))\n('ai', 186, datetime.datetime(2021, 10, 24, 15, 33, 50))\n('good', 16, datetime.datetime(2021, 10, 24, 15, 33, 50))\n('spark', 2, datetime.datetime(2021, 10, 24, 15, 33, 50))\n('data', 1, datetime.datetime(2021, 10, 24, 15, 33, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:33:55\n-------------------------------------------\n('#lalice', 165)\n('#blackpink', 165)\n('#lalisa', 165)\n('#bigil', 88)\n('#ai', 84)\n('#beast', 64)\n('#datascience', 64)\n('#machinelearning', 63)\n('#master', 58)\n('#2yrsofindustryhitbigil', 54)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:00\n-------------------------------------------\n('#lalice', 166)\n('#blackpink', 166)\n('#lalisa', 166)\n('#bigil', 88)\n('#ai', 86)\n('#datascience', 67)\n('#machinelearning', 66)\n('#beast', 65)\n('#master', 59)\n('#2yrsofindustryhitbigil', 55)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:05\n-------------------------------------------\n('#lalice', 172)\n('#blackpink', 172)\n('#lalisa', 172)\n('#bigil', 89)\n('#ai', 86)\n('#datascience', 67)\n('#beast', 66)\n('#machinelearning', 66)\n('#master', 60)\n('#2yrsofindustryhitbigil', 55)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:10\n-------------------------------------------\n('#lalice', 173)\n('#blackpink', 173)\n('#lalisa', 173)\n('#bigil', 89)\n('#ai', 86)\n('#datascience', 68)\n('#machinelearning', 67)\n('#beast', 66)\n('#master', 60)\n('#2yrsofindustryhitbigil', 55)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:15\n-------------------------------------------\n('#lalice', 175)\n('#blackpink', 175)\n('#lalisa', 175)\n('#bigil', 91)\n('#ai', 86)\n('#datascience', 68)\n('#machinelearning', 67)\n('#beast', 66)\n('#master', 60)\n('#2yrsofindustryhitbigil', 55)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:20\n-------------------------------------------\n('#lalice', 178)\n('#blackpink', 178)\n('#lalisa', 178)\n('#bigil', 92)\n('#ai', 87)\n('#datascience', 69)\n('#machinelearning', 68)\n('#beast', 66)\n('#master', 61)\n('#2yrsofindustryhitbigil', 56)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:25\n-------------------------------------------\n('#lalice', 181)\n('#blackpink', 181)\n('#lalisa', 181)\n('#bigil', 92)\n('#ai', 87)\n('#datascience', 69)\n('#machinelearning', 68)\n('#beast', 66)\n('#master', 61)\n('#2yrsofindustryhitbigil', 56)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:30\n-------------------------------------------\n('#lalice', 182)\n('#blackpink', 182)\n('#lalisa', 182)\n('#bigil', 93)\n('#ai', 87)\n('#datascience', 69)\n('#machinelearning', 68)\n('#beast', 67)\n('#master', 62)\n('#2yrsofindustryhitbigil', 56)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:35\n-------------------------------------------\n('#lalice', 184)\n('#blackpink', 184)\n('#lalisa', 184)\n('#bigil', 93)\n('#ai', 87)\n('#datascience', 69)\n('#machinelearning', 68)\n('#beast', 67)\n('#master', 62)\n('#2yrsofindustryhitbigil', 56)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:40\n-------------------------------------------\n('#lalice', 188)\n('#blackpink', 188)\n('#lalisa', 188)\n('#bigil', 94)\n('#ai', 87)\n('#datascience', 69)\n('#beast', 68)\n('#machinelearning', 68)\n('#master', 63)\n('#2yrsofindustryhitbigil', 57)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:45\n-------------------------------------------\n('#lalice', 189)\n('#blackpink', 189)\n('#lalisa', 189)\n('#bigil', 95)\n('#ai', 88)\n('#beast', 69)\n('#datascience', 69)\n('#machinelearning', 68)\n('#master', 65)\n('#2yrsofindustryhitbigil', 58)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:50\n-------------------------------------------\n('#lalice', 190)\n('#blackpink', 190)\n('#lalisa', 190)\n('#bigil', 97)\n('#ai', 89)\n('#datascience', 70)\n('#beast', 69)\n('#machinelearning', 69)\n('#master', 65)\n('#2yrsofindustryhitbigil', 58)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:34:50\n-------------------------------------------\n('movie', 290, datetime.datetime(2021, 10, 24, 15, 34, 50))\n('ai', 191, datetime.datetime(2021, 10, 24, 15, 34, 50))\n('good', 8, datetime.datetime(2021, 10, 24, 15, 34, 50))\n('spark', 6, datetime.datetime(2021, 10, 24, 15, 34, 50))\n('data', 3, datetime.datetime(2021, 10, 24, 15, 34, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:34:55\n-------------------------------------------\n('#lalice', 192)\n('#blackpink', 192)\n('#lalisa', 192)\n('#bigil', 98)\n('#ai', 90)\n('#beast', 71)\n('#datascience', 71)\n('#machinelearning', 69)\n('#master', 67)\n('#2yrsofindustryhitbigil', 59)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:00\n-------------------------------------------\n('#lalice', 192)\n('#blackpink', 192)\n('#lalisa', 192)\n('#bigil', 99)\n('#ai', 91)\n('#beast', 73)\n('#datascience', 71)\n('#machinelearning', 70)\n('#master', 69)\n('#2yrsofindustryhitbigil', 59)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:05\n-------------------------------------------\n('#lalice', 193)\n('#blackpink', 193)\n('#lalisa', 193)\n('#bigil', 99)\n('#ai', 92)\n('#beast', 74)\n('#machinelearning', 71)\n('#datascience', 71)\n('#master', 69)\n('#2yrsofindustryhitbigil', 60)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:10\n-------------------------------------------\n('#lalice', 193)\n('#blackpink', 193)\n('#lalisa', 193)\n('#bigil', 99)\n('#ai', 93)\n('#beast', 75)\n('#machinelearning', 71)\n('#datascience', 71)\n('#master', 69)\n('#2yrsofindustryhitbigil', 61)\n...\n\n"}, {"name": "stdout", "output_type": "stream", "text": "-------------------------------------------\nTime: 2021-10-24 15:35:15\n-------------------------------------------\n('#lalice', 195)\n('#blackpink', 195)\n('#lalisa', 195)\n('#bigil', 99)\n('#ai', 95)\n('#beast', 75)\n('#machinelearning', 72)\n('#datascience', 71)\n('#master', 69)\n('#2yrsofindustryhitbigil', 61)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:20\n-------------------------------------------\n('#lalice', 195)\n('#blackpink', 195)\n('#lalisa', 195)\n('#bigil', 99)\n('#ai', 96)\n('#beast', 75)\n('#machinelearning', 72)\n('#datascience', 71)\n('#master', 69)\n('#2yrsofindustryhitbigil', 61)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:25\n-------------------------------------------\n('#lalice', 195)\n('#blackpink', 195)\n('#lalisa', 195)\n('#bigil', 105)\n('#ai', 97)\n('#beast', 77)\n('#machinelearning', 72)\n('#master', 71)\n('#datascience', 71)\n('#2yrsofindustryhitbigil', 63)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:30\n-------------------------------------------\n('#lalice', 197)\n('#blackpink', 197)\n('#lalisa', 197)\n('#bigil', 106)\n('#ai', 98)\n('#beast', 78)\n('#master', 72)\n('#machinelearning', 72)\n('#datascience', 72)\n('#2yrsofindustryhitbigil', 64)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:35\n-------------------------------------------\n('#lalice', 198)\n('#blackpink', 198)\n('#lalisa', 198)\n('#bigil', 107)\n('#ai', 99)\n('#beast', 80)\n('#master', 74)\n('#datascience', 73)\n('#machinelearning', 72)\n('#2yrsofindustryhitbigil', 66)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:40\n-------------------------------------------\n('#lalice', 200)\n('#blackpink', 200)\n('#lalisa', 200)\n('#bigil', 108)\n('#ai', 101)\n('#beast', 82)\n('#master', 75)\n('#datascience', 75)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 68)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:45\n-------------------------------------------\n('#lalice', 202)\n('#blackpink', 202)\n('#lalisa', 202)\n('#bigil', 109)\n('#ai', 101)\n('#beast', 82)\n('#master', 75)\n('#datascience', 75)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 68)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:50\n-------------------------------------------\n('#lalice', 204)\n('#blackpink', 204)\n('#lalisa', 204)\n('#bigil', 109)\n('#ai', 101)\n('#beast', 82)\n('#master', 75)\n('#datascience', 75)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 68)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:35:50\n-------------------------------------------\n('ai', 214, datetime.datetime(2021, 10, 24, 15, 35, 50))\n('movie', 255, datetime.datetime(2021, 10, 24, 15, 35, 50))\n('good', 11, datetime.datetime(2021, 10, 24, 15, 35, 50))\n('spark', 9, datetime.datetime(2021, 10, 24, 15, 35, 50))\n('data', 4, datetime.datetime(2021, 10, 24, 15, 35, 50))\n\n-------------------------------------------\nTime: 2021-10-24 15:35:55\n-------------------------------------------\n('#lalice', 205)\n('#blackpink', 205)\n('#lalisa', 205)\n('#bigil', 110)\n('#ai', 102)\n('#beast', 83)\n('#master', 76)\n('#datascience', 76)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 69)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:00\n-------------------------------------------\n('#lalice', 206)\n('#blackpink', 206)\n('#lalisa', 206)\n('#bigil', 110)\n('#ai', 102)\n('#beast', 84)\n('#master', 76)\n('#datascience', 76)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 70)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:05\n-------------------------------------------\n('#lalice', 209)\n('#blackpink', 209)\n('#lalisa', 209)\n('#bigil', 112)\n('#ai', 102)\n('#beast', 84)\n('#master', 76)\n('#datascience', 76)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 70)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:10\n-------------------------------------------\n('#lalice', 211)\n('#blackpink', 211)\n('#lalisa', 211)\n('#bigil', 112)\n('#ai', 102)\n('#beast', 84)\n('#master', 76)\n('#datascience', 76)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 70)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:15\n-------------------------------------------\n('#lalice', 213)\n('#blackpink', 213)\n('#lalisa', 213)\n('#bigil', 114)\n('#ai', 103)\n('#beast', 84)\n('#master', 76)\n('#datascience', 76)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 71)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:20\n-------------------------------------------\n('#lalice', 216)\n('#blackpink', 216)\n('#lalisa', 216)\n('#bigil', 114)\n('#ai', 104)\n('#beast', 85)\n('#master', 77)\n('#datascience', 76)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 72)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:25\n-------------------------------------------\n('#lalice', 217)\n('#blackpink', 217)\n('#lalisa', 217)\n('#bigil', 115)\n('#ai', 104)\n('#beast', 86)\n('#master', 78)\n('#datascience', 77)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 72)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:30\n-------------------------------------------\n('#lalice', 217)\n('#blackpink', 217)\n('#lalisa', 217)\n('#bigil', 117)\n('#ai', 105)\n('#beast', 87)\n('#master', 79)\n('#datascience', 78)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 72)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:35\n-------------------------------------------\n('#lalice', 217)\n('#blackpink', 217)\n('#lalisa', 217)\n('#bigil', 118)\n('#ai', 107)\n('#beast', 87)\n('#master', 79)\n('#datascience', 78)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 72)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:40\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 118)\n('#ai', 108)\n('#beast', 87)\n('#master', 79)\n('#datascience', 78)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 72)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:45\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 119)\n('#ai', 108)\n('#beast', 87)\n('#master', 79)\n('#datascience', 78)\n('#machinelearning', 73)\n('#2yrsofindustryhitbigil', 72)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:36:50\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\nWaking up...\n-------------------------------------------\nTime: 2021-10-24 15:36:55\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:00\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:05\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:10\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:15\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:20\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n"}, {"name": "stdout", "output_type": "stream", "text": "-------------------------------------------\nTime: 2021-10-24 15:37:25\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:30\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:35\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:40\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:45\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:50\n-------------------------------------------\n('#lalice', 221)\n('#blackpink', 221)\n('#lalisa', 221)\n('#bigil', 120)\n('#ai', 108)\n('#beast', 88)\n('#master', 80)\n('#datascience', 78)\n('#2yrsofindustryhitbigil', 73)\n('#machinelearning', 73)\n...\n\n-------------------------------------------\nTime: 2021-10-24 15:37:50\n-------------------------------------------\n\nSaving to BigQuery\nDone :) \n"}], "source": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Columbia EECS E6893 Big Data Analytics\n\"\"\"\nThis module is the spark streaming analysis process.\n\n\nUsage:\n    If used with dataproc:\n        gcloud dataproc jobs submit pyspark --cluster <Cluster Name> twitterHTTPClient.py\n\n    Create a dataset in BigQurey first using\n        bq mk bigdata_sparkStreaming\n\n    Remeber to replace the bucket with your own bucket name\n\n\nTodo:\n    1. hashtagCount: calculate accumulated hashtags count\n    2. wordCount: calculate word count every 60 seconds\n        the word you should track is listed below.\n    3. save the result to google BigQuery\n\n\"\"\"\n\nfrom pyspark import SparkConf,SparkContext\nfrom pyspark.streaming import StreamingContext\nfrom pyspark.sql import Row,SQLContext\nimport sys\nimport requests\nimport time\nimport subprocess\nimport re\nfrom google.cloud import bigquery\n\n# global variables\nbucket = \"mk4427hw2\"    # TODO : replace with your own bucket name\noutput_directory_hashtags = 'gs://{}/hadoop/tmp/bigquery/pyspark_output/hashtagsCount'.format(bucket)\noutput_directory_wordcount = 'gs://{}/hadoop/tmp/bigquery/pyspark_output/wordcount'.format(bucket)\n\n# output table and columns name\noutput_dataset = 'mk4427data'                     #the name of your dataset in BigQuery\noutput_table_hashtags = 'hashtags'\ncolumns_name_hashtags = ['hashtags', 'count']\noutput_table_wordcount = 'wordcount'\ncolumns_name_wordcount = ['word', 'count', 'time']\n\n# parameter\nIP = 'localhost'    # ip port\nPORT = 9001       # port\n\nSTREAMTIME = 600      # time that the streaming process runs\n\nWORD = ['data', 'spark', 'ai', 'movie', 'good']     #the words you should filter and do word count\n\n# Helper functions\ndef saveToStorage(rdd, output_directory, columns_name, mode):\n    \"\"\"\n    Save each RDD in this DStream to google storage\n    Args:\n        rdd: input rdd\n        output_directory: output directory in google storage\n        columns_name: columns name of dataframe\n        mode: mode = \"overwirte\", overwirte the file\n              mode = \"append\", append data to the end of file\n    \"\"\"\n    if not rdd.isEmpty():\n        (rdd.toDF( columns_name ) \\\n        .write.save(output_directory, format=\"json\", mode=mode))\n\n\ndef saveToBigQuery(sc, output_dataset, output_table, directory):\n    \"\"\"\n    Put temp streaming json files in google storage to google BigQuery\n    and clean the output files in google storage\n    \"\"\"\n    files = directory + '/part-*'\n    subprocess.check_call(\n        'bq load --source_format NEWLINE_DELIMITED_JSON '\n        '--replace '\n        '--autodetect '\n        '{dataset}.{table} {files}'.format(\n            dataset=output_dataset, table=output_table, files=files\n        ).split())\n    output_path = sc._jvm.org.apache.hadoop.fs.Path(directory)\n    output_path.getFileSystem(sc._jsc.hadoopConfiguration()).delete(\n        output_path, True)\n\n\ndef hashtagCount(words):\n    \"\"\"\n    Calculate the accumulated hashtags count sum from the beginning of the stream\n    and sort it by descending order of the count.\n    Ignore case sensitivity when counting the hashtags:\n        \"#Ab\" and \"#ab\" is considered to be a same hashtag\n    You have to:\n    1. Filter out the word that is hashtags.\n       Hashtag usually start with \"#\" and followed by a serious of alphanumeric\n    2. map (hashtag) to (hashtag, 1)\n    3. sum the count of current DStream state and previous state\n    4. transform unordered DStream to a ordered Dstream\n    Hints:\n        you may use regular expression to filter the words\n        You can take a look at updateStateByKey and transform transformations\n    Args:\n        dstream(DStream): stream of real time tweets\n    Returns:\n        DStream Object with inner structure (hashtag, count)\n    \"\"\"\n\n    # TODO: insert your code here\n    tagCounts = words.filter(lambda word: word.lower().startswith(\"#\") and re.match('^[a-zA-Z0-9]+$',\n                                                                                    word[1:])).\\\n                map(lambda word:(word.lower(),1))\n    tagCounts = tagCounts.updateStateByKey(lambda x,y: sum(x)+(y or 0))\n    return tagCounts.transform(lambda rdd: rdd.sortBy(lambda x: x[1],\n                                                      ascending=False))\n\ndef wordCount(words):\n    \"\"\"\n    Calculte the count of 5 sepcial words for every 60 seconds (window no overlap)\n    You can choose your own words.\n    Your should:\n    1. filter the words\n    2. count the word during a special window size\n    3. add a time related mark to the output of each window, ex: a datetime type\n    Hints:\n        You can take a look at reduceByKeyAndWindow transformation\n        Dstream is a serious of rdd, each RDD in a DStream contains data from a certain interval\n        You may want to take a look of transform transformation of DStream when trying to add a time\n    Args:\n        dstream(DStream): stream of real time tweets\n    Returns:\n        DStream Object with inner structure (word, (count, time))\n    \"\"\"\n\n    # TODO: insert your code here\n    selected = words.filter(lambda x: any(word == x.lower() for word in WORD)).\\\n                map(lambda word:(word.lower(),1))\n    counts = selected.reduceByKeyAndWindow(lambda key, window: key + window,\n                                           lambda key, window: key - window,\n                                           60,\n                                           60)\n    return counts.transform(lambda time, rdd: rdd.map(lambda x: (x[0],\n                                                                 x[1],\n                                                                 time)))\n\ndef saveToStorage_hashTags(rdd):\n    if not rdd.isEmpty():\n        (rdd.toDF( columns_name_hashtags ) \\\n        .write.save(output_directory_hashtags, format=\"json\", mode=\"overwrite\"))\n\ndef saveToStorage_wordCount(rdd):\n    if not rdd.isEmpty():\n        (rdd.toDF( columns_name_wordcount ) \\\n        .write.save(output_directory_wordcount, format=\"json\", mode=\"append\"))\n\nif __name__ == '__main__':\n    # Spark settings\n    conf = SparkConf()\n    conf.setMaster('local[2]')\n    conf.setAppName(\"TwitterStreamApp\")\n\n    # create spark context with the above configuration\n    sc = SparkContext.getOrCreate(conf=conf)\n    sc.setLogLevel(\"ERROR\")\n\n    # create sql context, used for saving rdd\n    sql_context = SQLContext(sc)\n\n    # create the Streaming Context from the above spark context with batch interval size 5 seconds\n    ssc = StreamingContext(sc, 5)\n    # setting a checkpoint to allow RDD recovery\n    ssc.checkpoint(\"~/checkpoint_TwitterApp\")\n\n    # read data from port 9001\n    dataStream = ssc.socketTextStream(IP, PORT)\n    #dataStream.pprint()\n\n    words = dataStream.flatMap(lambda line: line.split(\" \"))\n    #words.pprint()\n    # calculate the accumulated hashtags count sum from the beginning of the stream\n    topTags = hashtagCount(words)\n    topTags.pprint()\n\n    # Calculte the word count during each time period 6s\n    wordCount = wordCount(words)\n    wordCount.pprint()\n\n    # save hashtags count and word count to google storage\n    # used to save to google BigQuery\n    # You should:\n    #   1. topTags: only save the lastest rdd in DStream\n    #   2. wordCount: save each rdd in DStream\n    # Hints:\n    #   1. You can take a look at foreachRDD transformation\n    #   2. You may want to use helper function saveToStorage\n    #   3. You should use save output to output_directory_hashtags, output_directory_wordcount,\n    #       and have output columns name columns_name_hashtags and columns_name_wordcount.\n    # TODO: insert your code here\n    \n    topTags.foreachRDD(saveToStorage_hashTags)\n    wordCount.foreachRDD(saveToStorage_wordCount)\n    print(\"Starting ssc\")\n    # start streaming process, wait for 600s and then stop.\n    ssc.start()\n    print(\"Sleeping .....zzzz..\")\n    time.sleep(STREAMTIME)\n    print(\"Waking up...\")\n    ssc.stop(stopSparkContext=False, stopGraceFully=True)\n    print(\"Saving to BigQuery\")\n    # put the temp result in google storage to google BigQuery\n    saveToBigQuery(sc, output_dataset, output_table_wordcount, output_directory_wordcount)\n    saveToBigQuery(sc, output_dataset, output_table_hashtags, output_directory_hashtags)\n    print(\"Done :) \")\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}}, "nbformat": 4, "nbformat_minor": 2}